---
title: 基于三种不同方法的多元回归
date: 2022-10-19
katex: true
tags: ["linguistic","regression"]
---



## 多元回归分析-机器学习

### 公式推导

对于一个多元回归，与一元回归类似，其函数表达为
`$$
Y_i=\beta_0+\beta_1X_1+\beta_2X_2\cdots+\beta_nX_n+\mu_i
$$`
写成矩阵的形式：
`$$
f(x_i)=\omega^Tx_i+b
$$`


我们为简便处理，将原有的参数`$\omega $`和参数`$b$`合并：
`$$ w'=w^T+b$$`
同时`$X$`对应的变动:
`$$
X'=X+\begin{bmatrix}
1\\\vdots \\1
\end{bmatrix}=(x_1,x_2,\cdots,x_n,\mathbb{1})
$$`

与一元回归相同：损失函数(loss function) 使用最小二乘，也就是预测值与实际值的平方项最小。
`$$
\hat \omega^*=\arg\min_{\hat\omega}(y-X'\hat{\omega})^T(y-X'\hat\omega)
$$`
当`$X^TX$`为满秩或正定矩阵时候，求导得到：
`$$
\hat \omega=(X'^TX')^{-1}X'^Ty
$$`

### 数据预处理

导入包


```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
```

导入本地数据：一个班级学生基本信息：性别、年龄、身高和体重的数据


```python
df=pd.read_csv("/Users/a182501/class.csv")
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>sex</th>
      <th>age</th>
      <th>height</th>
      <th>weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alice</td>
      <td>F</td>
      <td>13</td>
      <td>56.5</td>
      <td>84.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Becka</td>
      <td>F</td>
      <td>13</td>
      <td>65.3</td>
      <td>98.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gail</td>
      <td>F</td>
      <td>14</td>
      <td>64.3</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Karen</td>
      <td>F</td>
      <td>12</td>
      <td>56.3</td>
      <td>77.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Kathy</td>
      <td>F</td>
      <td>12</td>
      <td>59.8</td>
      <td>84.5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>69</th>
      <td>Sharon</td>
      <td>M</td>
      <td>15</td>
      <td>59.8</td>
      <td>102.5</td>
    </tr>
    <tr>
      <th>70</th>
      <td>Tammy</td>
      <td>M</td>
      <td>14</td>
      <td>66.5</td>
      <td>84.0</td>
    </tr>
    <tr>
      <th>71</th>
      <td>Alfred</td>
      <td>M</td>
      <td>15</td>
      <td>51.3</td>
      <td>102.5</td>
    </tr>
    <tr>
      <th>72</th>
      <td>Duke</td>
      <td>M</td>
      <td>17</td>
      <td>62.5</td>
      <td>133.0</td>
    </tr>
    <tr>
      <th>73</th>
      <td>Guido</td>
      <td>M</td>
      <td>15</td>
      <td>62.8</td>
      <td>83.0</td>
    </tr>
  </tbody>
</table>
<p>74 rows × 5 columns</p>
</div>



数据的转换：将原有的`sex`的字符串转换为数值形式


```python
for i in range(len(df)):
    if(df.sex[i]== 'F' ):
        df.sex[i]=0
    else:
        df.sex[i]=1
```

    /var/folders/sn/g01cvq2j72j6tbq2pmmm074h0000gq/T/ipykernel_76758/3328237516.py:3: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df.sex[i]=0
    /var/folders/sn/g01cvq2j72j6tbq2pmmm074h0000gq/T/ipykernel_76758/3328237516.py:5: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      df.sex[i]=1


添加数据的常量


```python
y=df.sex
X_c=sm.add_constant(X)
X_c
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>const</th>
      <th>age</th>
      <th>height</th>
      <th>weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>13</td>
      <td>56.5</td>
      <td>84.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>13</td>
      <td>65.3</td>
      <td>98.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>14</td>
      <td>64.3</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>12</td>
      <td>56.3</td>
      <td>77.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>12</td>
      <td>59.8</td>
      <td>84.5</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>69</th>
      <td>1.0</td>
      <td>15</td>
      <td>59.8</td>
      <td>102.5</td>
    </tr>
    <tr>
      <th>70</th>
      <td>1.0</td>
      <td>14</td>
      <td>66.5</td>
      <td>84.0</td>
    </tr>
    <tr>
      <th>71</th>
      <td>1.0</td>
      <td>15</td>
      <td>51.3</td>
      <td>102.5</td>
    </tr>
    <tr>
      <th>72</th>
      <td>1.0</td>
      <td>17</td>
      <td>62.5</td>
      <td>133.0</td>
    </tr>
    <tr>
      <th>73</th>
      <td>1.0</td>
      <td>15</td>
      <td>62.8</td>
      <td>83.0</td>
    </tr>
  </tbody>
</table>
<p>74 rows × 4 columns</p>
</div>



### 利用公式推导求参


```python
XT=X_c.T
a2=np.linalg.inv(XT @ X_c)
a3=a2 @ XT
a3@y
```




    0    0.448582
    1   -0.076499
    2    0.012579
    3    0.004838
    dtype: object



### 使用`package`的方法


```python
est = sm.OLS(y.astype(float), X_c.astype(float)).fit()
```


```python
print(est.summary())
```

                                OLS Regression Results                            
    ==============================================================================
    Dep. Variable:                    sex   R-squared:                       0.079
    Model:                            OLS   Adj. R-squared:                  0.040
    Method:                 Least Squares   F-statistic:                     2.004
    Date:                Wed, 19 Oct 2022   Prob (F-statistic):              0.121
    Time:                        20:47:38   Log-Likelihood:                -47.853
    No. Observations:                  74   AIC:                             103.7
    Df Residuals:                      70   BIC:                             112.9
    Df Model:                           3                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    const          0.4486      0.757      0.593      0.555      -1.061       1.958
    age           -0.0765      0.039     -1.969      0.053      -0.154       0.001
    height         0.0126      0.014      0.913      0.364      -0.015       0.040
    weight         0.0048      0.003      1.546      0.127      -0.001       0.011
    ==============================================================================
    Omnibus:                      108.726   Durbin-Watson:                   0.245
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):                9.450
    Skew:                          -0.443   Prob(JB):                      0.00887
    Kurtosis:                       1.490   Cond. No.                     1.66e+03
    ==============================================================================
    
    Notes:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The condition number is large, 1.66e+03. This might indicate that there are
    strong multicollinearity or other numerical problems.


### 利用优化求参


```python
from pandas import array
def model1(a):
    return (a[0]+X@a[1:])
model1(np.array([0,1,2,3]))
```




    0     378.0
    1     437.6
    2     412.6
    3     355.6
    4     385.1
          ...  
    69    442.1
    70    399.0
    71    425.1
    72    541.0
    73    389.6
    Length: 74, dtype: float64




```python
import math
def objective(mod):
    diff=y-model1(mod)
    diff2=pow(diff,2)
    return(diff2.mean())
    #sqrt(np.mean(diff^2))
objective(array([0,0.1,0.1,0.1]))  #a test for objective function
```




    297.83417297297296



设置一个随机数组生成器，同时控制随机数的范围


```python
from scipy.optimize import minimize
from numpy.random import rand
r_min,r_max = -1.0,1.0
# 生成随机初始值
pt = r_min + rand(4) * (r_max - r_min) 
```

调用`scipy.optimize`一个`minimize`函数来实现优化算法；这里采用的是BFGS算法，其余还可以选择牛顿迭代等算法


```python
result = minimize(objective,pt,method='L-BFGS-B')
```

得到参数结果


```python
result.x
```




    array([ 0.44864376, -0.07655835,  0.0125904 ,  0.00483854])



### 总结


- 本文利用从一元回归推导至多元回归的方式来得到`$\omega$`的表达式，最后能够从三个方面求解在OLS下的最优参数；
- 第一个最为简单的方式是通过调用`statsmodels.api`包的方式来实现，能够很快的估计出参数；
  - 该方法的不足之处在于对于模型的较为固定，无法实现其他的转变；
- 第二个方法是通过从一元回归推导至多元回归的方式来得到`$\omega$`的表达式，最终能够获取参数。
  - 该方法可能存在对于逆的求解上可能较为困难，尤其是当数据量较大时候，需要采用一些优化诸如LU分解等算法，对于数学要求较高
- 第三个方法是从优化迭代的角度来寻找参数，因我们的目标函数是在寻求最小的均方差，以此设定参数初值和迭代方法来进行迭代，最终能够找到最小均方差下的参数的最优值
- 本文一大问题是在于没有能够分类训练集和测试集，侧重于参数的寻找，因此需要改进的方向在于完善整个的寻参过程。
